{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb8ac99e-331d-496a-9486-ca496fb08221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from galaxy_mnist import GalaxyMNIST\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5db74ccb-44cf-4c49-bc68-7b2249c4f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation for the dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load the GalaxyMNIST dataset\n",
    "train_dataset = GalaxyMNIST(\n",
    "    root='ML_DP/gal_mnist',\n",
    "    download=True,\n",
    "    train=True  # by default, or False for canonical test set\n",
    ")\n",
    "test_dataset = GalaxyMNIST(\n",
    "    root='ML_DP/gal_mnist',\n",
    "    download=True,\n",
    "    train=False  # by default, or False for canonical test set\n",
    ")\n",
    "\n",
    "# images (as tensors) and labels\n",
    "train_images = (train_dataset.data)\n",
    "train_label = (train_dataset.targets)\n",
    "\n",
    "test_images = (test_dataset.data)\n",
    "test_label = (test_dataset.targets)\n",
    "\n",
    "# create pytorch dataset\n",
    "train_dataset = TensorDataset(train_images, train_label)\n",
    "test_dataset = TensorDataset(test_images, test_label)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "358eedc9-ea5b-4680-b65f-2fad9c9559b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class GalaxyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GalaxyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 14 * 14, 128)\n",
    "        self.fc2 = nn.Linear(128, 4)  # 4 classes for classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 14 * 14)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5d93b04-5d6f-4d52-97e5-16f926244190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7640277147293091\n",
      "Epoch [1/10], Loss: 0.7640\n",
      "0.5413082242012024\n",
      "Epoch [2/10], Loss: 0.5413\n",
      "0.4992194175720215\n",
      "Epoch [3/10], Loss: 0.4992\n",
      "0.4143455922603607\n",
      "Epoch [4/10], Loss: 0.4143\n",
      "0.8527770042419434\n",
      "Epoch [5/10], Loss: 0.8528\n",
      "0.28456756472587585\n",
      "Epoch [6/10], Loss: 0.2846\n",
      "0.4067787528038025\n",
      "Epoch [7/10], Loss: 0.4068\n",
      "0.2947241961956024\n",
      "Epoch [8/10], Loss: 0.2947\n",
      "0.2844594419002533\n",
      "Epoch [9/10], Loss: 0.2845\n",
      "0.19354501366615295\n",
      "Epoch [10/10], Loss: 0.1935\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model, loss function, and optimizer\n",
    "model = GalaxyCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "train_loss = np.zeros(num_epochs)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images = images.float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss[epoch] = loss\n",
    "    print(train_loss[epoch])\n",
    "    # Print training loss\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e98f4c9c-7f91-4cbe-ba3e-02ff6d7f5398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 74.05%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.float()\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
